{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LHydra Recommender System\n",
        "\n",
        "This notebook demonstrates the revised implementation of the ReNeLLM-based recommender system, incorporating the following improvements:\n",
        "\n",
        "1. **Data Preprocessing Pipeline**\n",
        "2. **Consistent Handling of Encoders and Vectorizers**\n",
        "3. **Enhanced Model Training**\n",
        "4. **Improved Inference Function**\n",
        "5. **Optimized Recommendation Generation**\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Import Necessary Modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from preprocessing import DataPreprocessor\n",
        "from model import HybridRecommender\n",
        "from inference import get_recommendations, make_inference\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load Pretrained Model and Preprocessors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'track_name'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "File \u001b[0;32m~/anaconda3/envs/ReNeLLM/lib/python3.9/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
            "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'track_name'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[3], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m data \u001b[38;5;241m=\u001b[39m preprocessor\u001b[38;5;241m.\u001b[39mload_data(filepath)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Encoding features\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m data_encoded \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m features \u001b[38;5;241m=\u001b[39m preprocessor\u001b[38;5;241m.\u001b[39mfeature_engineering(data_encoded)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Splitting data\u001b[39;00m\n",
            "File \u001b[0;32m~/Lhydra_rs/rs_main/preprocessing.py:50\u001b[0m, in \u001b[0;36mDataPreprocessor.encode_features\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     48\u001b[0m artist_tfidf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39martist_tfidf_vectorizer\u001b[38;5;241m.\u001b[39mfit_transform(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124martist_name\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# Assuming 'track_name' instead of 'music_id' for TF-IDF; adjust as needed\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m track_tfidf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39martist_tfidf_vectorizer\u001b[38;5;241m.\u001b[39mfit_transform(\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrack_name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Ensure TF-IDF dimensions are consistent\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArtist TF-IDF Shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00martist_tfidf\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Should be (num_samples, artist_tfidf_features)\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/envs/ReNeLLM/lib/python3.9/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
            "File \u001b[0;32m~/anaconda3/envs/ReNeLLM/lib/python3.9/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
            "\u001b[0;31mKeyError\u001b[0m: 'track_name'"
          ]
        }
      ],
      "source": [
        "preprocessor = DataPreprocessor()\n",
        "filepath = '../data/cleaned_modv2.csv'\n",
        "data = preprocessor.load_data(filepath)\n",
        "\n",
        "# Encoding features\n",
        "data_encoded = preprocessor.encode_features(data)\n",
        "features = preprocessor.feature_engineering(data_encoded)\n",
        "\n",
        "# Splitting data\n",
        "train_features, test_features, train_target, test_target = preprocessor.split_data(features)\n",
        "\n",
        "# Save preprocessors\n",
        "preprocessor.save_preprocessors(directory='models/')\n",
        "\n",
        "# Load preprocessors\n",
        "preprocessor.load_preprocessors(directory='models/')\n",
        "\n",
        "# Verify loaded preprocessors\n",
        "print(\"Preprocessors loaded successfully.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model and preprocessors loaded successfully.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_1107/945155707.py:22: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('models/model.pth', map_location=device))\n"
          ]
        }
      ],
      "source": [
        "# Load the trained model\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "num_users = len(preprocessor.user_id_encoder.classes_)\n",
        "num_artists = len(preprocessor.artist_encoder.classes_)  # Ensure you have artist_encoder\n",
        "num_tracks = len(preprocessor.track_encoder.classes_)    # Ensure you have track_encoder\n",
        "num_genres = len(preprocessor.genre_encoder.classes_)\n",
        "embedding_dim = 128\n",
        "num_audio_features = train_features.shape[1] - (preprocessor.user_id_encoder.classes_.shape[0] + \n",
        "                                             preprocessor.artist_encoder.classes_.shape[0] +\n",
        "                                             preprocessor.track_encoder.classes_.shape[0] +\n",
        "                                             preprocessor.genre_encoder.classes_.shape[0] + 1) # Adjust as per actual features\n",
        "\n",
        "model = HybridRecommender(\n",
        "    num_users=num_users,\n",
        "    num_artists=num_artists,\n",
        "    num_tracks=num_tracks,\n",
        "    num_genres=num_genres,\n",
        "    embedding_dim=embedding_dim,\n",
        "    num_audio_features=num_audio_features,\n",
        "    num_layers=3,\n",
        "    hidden_dims=[256, 128, 64],\n",
        "    dropout_prob=0.2\n",
        ")\n",
        "model.load_state_dict(torch.load('models/model.pth', map_location=device))\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "print(\"Model and preprocessors loaded successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "12113"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "num_features\n",
        "# train_features.shape[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(19974, 12114)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "features.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "12113"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_features.shape[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train User features shape: (15979, 6099)\n",
            "Train item features shape: (15979, 2)\n"
          ]
        }
      ],
      "source": [
        "user_features = train_features[train_features.columns[:num_features]]\n",
        "item_features = train_features[train_features.columns[num_features:]]\n",
        "user_features.shape, item_features.shape\n",
        "print(f\"Train User features shape: {user_features.shape}\\nTrain item features shape: {item_features.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test user features shape: (3995, 6099)\n",
            "Test item features shape: (3995, 2)\n"
          ]
        }
      ],
      "source": [
        "test_user_features = test_features[test_features.columns[:num_features]]\n",
        "test_item_features = test_features[test_features.columns[num_features:]]\n",
        "print(f\"Test user features shape: {test_user_features.shape}\\nTest item features shape: {test_item_features.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Generate Recommendations for a User"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random user id: 32261\n"
          ]
        }
      ],
      "source": [
        "random_user_id = data['user_id'].sample(1).values[0]\n",
        "print(f\"Random user id: {random_user_id}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>age</th>\n",
              "      <th>gender</th>\n",
              "      <th>music</th>\n",
              "      <th>artist_name</th>\n",
              "      <th>featured_artists</th>\n",
              "      <th>genre</th>\n",
              "      <th>plays</th>\n",
              "      <th>duration</th>\n",
              "      <th>music_id</th>\n",
              "      <th>...</th>\n",
              "      <th>speechiness</th>\n",
              "      <th>instrumentalness</th>\n",
              "      <th>liveness</th>\n",
              "      <th>valence</th>\n",
              "      <th>tempo</th>\n",
              "      <th>time_signature</th>\n",
              "      <th>explicit</th>\n",
              "      <th>user_id_encoded</th>\n",
              "      <th>music_id_encoded</th>\n",
              "      <th>gender_encoded</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>634</th>\n",
              "      <td>32261</td>\n",
              "      <td>47</td>\n",
              "      <td>F</td>\n",
              "      <td>I Fall Apart</td>\n",
              "      <td>Post Malone</td>\n",
              "      <td>MKTO, Charli XCX</td>\n",
              "      <td>Rap</td>\n",
              "      <td>12</td>\n",
              "      <td>3.72</td>\n",
              "      <td>75ZvA4QfFiZvzhj2xkaWAh</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0327</td>\n",
              "      <td>7.566667e-07</td>\n",
              "      <td>0.281133</td>\n",
              "      <td>0.261667</td>\n",
              "      <td>138.843</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3198</td>\n",
              "      <td>3677</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>635</th>\n",
              "      <td>32261</td>\n",
              "      <td>47</td>\n",
              "      <td>F</td>\n",
              "      <td>Feelin' It</td>\n",
              "      <td>Home Free</td>\n",
              "      <td>none</td>\n",
              "      <td>Classical</td>\n",
              "      <td>1</td>\n",
              "      <td>3.05</td>\n",
              "      <td>14cikDRwGYOB1UfdA44V4P</td>\n",
              "      <td>...</td>\n",
              "      <td>0.1277</td>\n",
              "      <td>1.673333e-01</td>\n",
              "      <td>0.199333</td>\n",
              "      <td>0.711667</td>\n",
              "      <td>88.286</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3198</td>\n",
              "      <td>2515</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 27 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     user_id  age gender         music  artist_name  featured_artists  \\\n",
              "634    32261   47      F  I Fall Apart  Post Malone  MKTO, Charli XCX   \n",
              "635    32261   47      F    Feelin' It    Home Free              none   \n",
              "\n",
              "         genre  plays  duration                music_id  ... speechiness  \\\n",
              "634        Rap     12      3.72  75ZvA4QfFiZvzhj2xkaWAh  ...      0.0327   \n",
              "635  Classical      1      3.05  14cikDRwGYOB1UfdA44V4P  ...      0.1277   \n",
              "\n",
              "     instrumentalness  liveness   valence    tempo  time_signature  explicit  \\\n",
              "634      7.566667e-07  0.281133  0.261667  138.843             4.0       0.0   \n",
              "635      1.673333e-01  0.199333  0.711667   88.286             4.0       0.0   \n",
              "\n",
              "     user_id_encoded  music_id_encoded  gender_encoded  \n",
              "634             3198              3677               0  \n",
              "635             3198              2515               0  \n",
              "\n",
              "[2 rows x 27 columns]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data[data['user_id'] == random_user_id]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "User Features Shape: torch.Size([1, 6099])\n",
            "Item IDs Shape: torch.Size([9470])\n",
            "User IDs Shape: torch.Size([9470])\n",
            "Repeated Features Shape: torch.Size([9470, 6099])\n",
            "Scores Shape: torch.Size([9470])\n",
            "Top 10 recommendations for user 2456:\n",
            "1. (I Can't Get No) Satisfaction\n",
            "2. (Have You Heard The News) Dewey Cox Died\n",
            "3. (Everything I Do) I Do It For You\n",
            "4. (Ghost) Riders in the Sky\n",
            "5. 'Round Midnight\n",
            "6. $TING\n",
            "7. 'Til I Die\n",
            "8. (Don't Fear) The Reaper\n",
            "9. (I've Had) The Time of My Life\n",
            "10. (Let's Have A) Party\n"
          ]
        }
      ],
      "source": [
        "# Define user ID for whom recommendations are to be generated\n",
        "user_id = '2456'  # Replace with an actual user ID from your dataset\n",
        "top_k = 10\n",
        "\n",
        "try:\n",
        "    recommended_items = get_recommendations(\n",
        "        model=model,\n",
        "        user_id=user_id,\n",
        "        data_encoded=data_encoded,\n",
        "        user_id_encoder=preprocessor.user_id_encoder,\n",
        "        artist_encoder=preprocessor.artist_encoder,\n",
        "        track_encoder=preprocessor.track_encoder,\n",
        "        genre_encoder=preprocessor.genre_encoder,\n",
        "        music_id_to_info=music_id_to_info,  # Ensure this is defined\n",
        "        device=device,\n",
        "        top_k=top_k\n",
        "    )\n",
        "    print(f\"Top {top_k} recommendations for user {user_id}:\")\n",
        "    for idx, item in enumerate(recommended_items, start=1):\n",
        "        print(f\"{idx}. {item[0]} by {item[1]}\")\n",
        "except ValueError as ve:\n",
        "    print(ve)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0        83811\n",
              "1        83811\n",
              "2        13397\n",
              "3        70645\n",
              "4        70645\n",
              "         ...  \n",
              "19969    74433\n",
              "19970    74433\n",
              "19971    94134\n",
              "19972    78124\n",
              "19973    78124\n",
              "Name: user_id, Length: 19974, dtype: int64"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data['user_id']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original user ID: 35\n",
            "Encoded user ID: [2]\n",
            "Encoded user ID [2] not found in encoder.\n"
          ]
        }
      ],
      "source": [
        "# Define user ID for whom recommendations are to be generated\n",
        "user_id = \"35\"  # Replace with an actual user ID from your dataset\n",
        "top_k = 10\n",
        "\n",
        "try:\n",
        "    # Debug: Print the user ID before encoding\n",
        "    print(f\"Original user ID: {user_id}\")\n",
        "\n",
        "    # Debug: Print the encoded user ID\n",
        "    encoded_user_id = preprocessor.user_id_encoder.transform([user_id])\n",
        "    print(f\"Encoded user ID: {encoded_user_id}\")\n",
        "\n",
        "    # Check if the encoded user ID exists in the encoder's classes\n",
        "    if encoded_user_id[0] not in preprocessor.user_id_encoder.classes_:\n",
        "        raise ValueError(f\"Encoded user ID {encoded_user_id} not found in encoder.\")\n",
        "\n",
        "    recommended_items = get_recommendations(\n",
        "        model=model,\n",
        "        user_id=encoded_user_id,\n",
        "        data_encoded=data_encoded,\n",
        "        user_id_encoder=preprocessor.user_id_encoder,\n",
        "        item_encoder=preprocessor.music_id_encoder,\n",
        "        device=device,\n",
        "        top_k=top_k\n",
        "    )\n",
        "    print(f\"Top {top_k} recommendations for user {user_id}:\")\n",
        "    for idx, item in enumerate(recommended_items, start=1):\n",
        "        print(f\"{idx}. {item}\")\n",
        "except ValueError as ve:\n",
        "    print(ve)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[    4    16    35 ... 99996 99997 99998]\n"
          ]
        }
      ],
      "source": [
        "# print(preprocessor.user_id_encoder.classes_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>user_id_encoded</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>83811</td>\n",
              "      <td>8175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>83811</td>\n",
              "      <td>8175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13397</td>\n",
              "      <td>1294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>70645</td>\n",
              "      <td>6890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>70645</td>\n",
              "      <td>6890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19969</th>\n",
              "      <td>74433</td>\n",
              "      <td>7268</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19970</th>\n",
              "      <td>74433</td>\n",
              "      <td>7268</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19971</th>\n",
              "      <td>94134</td>\n",
              "      <td>9154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19972</th>\n",
              "      <td>78124</td>\n",
              "      <td>7639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19973</th>\n",
              "      <td>78124</td>\n",
              "      <td>7639</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>19974 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       user_id  user_id_encoded\n",
              "0        83811             8175\n",
              "1        83811             8175\n",
              "2        13397             1294\n",
              "3        70645             6890\n",
              "4        70645             6890\n",
              "        ...              ...\n",
              "19969    74433             7268\n",
              "19970    74433             7268\n",
              "19971    94134             9154\n",
              "19972    78124             7639\n",
              "19973    78124             7639\n",
              "\n",
              "[19974 rows x 2 columns]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data[['user_id','user_id_encoded']]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original user ID: 2456\n",
            "Encoded user ID: [228]\n",
            "Encoded user ID [228] not found in encoder. Handling as OOV...\n",
            "Assigned Default ID for OOV User: [9740]\n",
            "An error occurred: get_recommendations() got an unexpected keyword argument 'encoded_user_id'\n"
          ]
        }
      ],
      "source": [
        "\n",
        "try:\n",
        "    # Debug: Print the user ID before encoding\n",
        "    print(f\"Original user ID: {user_id}\")\n",
        "    \n",
        "    # Attempt transformation\n",
        "    encoded_user_id = preprocessor.user_id_encoder.transform([user_id])\n",
        "    print(f\"Encoded user ID: {encoded_user_id}\")\n",
        "    \n",
        "    # Check if the encoded user ID exists in the encoder's classes\n",
        "    if encoded_user_id[0] not in preprocessor.user_id_encoder.classes_:\n",
        "        print(f\"Encoded user ID {encoded_user_id} not found in encoder. Handling as OOV...\")\n",
        "        # Handle OOV user (e.g., assign default ID)\n",
        "        encoded_user_id = [preprocessor.user_id_encoder.classes_.shape[0] - 1]\n",
        "        print(f\"Assigned Default ID for OOV User: {encoded_user_id}\")\n",
        "    \n",
        "    recommended_items = get_recommendations(\n",
        "        model=model,\n",
        "        user_id=user_id,  # Pass original user ID for logging clarity\n",
        "        encoded_user_id=encoded_user_id,  # Updated to reflect potential OOV handling\n",
        "        data_encoded=data_encoded,\n",
        "        user_id_encoder=preprocessor.user_id_encoder,\n",
        "        item_encoder=preprocessor.music_id_encoder,\n",
        "        device=device,\n",
        "        top_k=top_k\n",
        "    )\n",
        "    print(f\"Top {top_k} recommendations for user {user_id}:\")\n",
        "    for idx, item in enumerate(recommended_items, start=1):\n",
        "        print(f\"{idx}. {item}\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original user ID: 2456\n",
            "Encoded user ID: [228]\n",
            "Encoded user ID [228] not found in encoder. Handling as OOV...\n",
            "Assigned Default ID for OOV User: [9740]\n",
            "User Features Shape: torch.Size([1, 6099])\n",
            "Item IDs Shape: torch.Size([9470])\n",
            "User IDs Shape: torch.Size([9470])\n",
            "Repeated Features Shape: torch.Size([9470, 6099])\n",
            "Scores Shape: torch.Size([9470])\n",
            "Top 10 recommendations for user 2456:\n",
            "1. (I Can't Get No) Satisfaction\n",
            "2. (Have You Heard The News) Dewey Cox Died\n",
            "3. (Everything I Do) I Do It For You\n",
            "4. (Ghost) Riders in the Sky\n",
            "5. 'Round Midnight\n",
            "6. $TING\n",
            "7. 'Til I Die\n",
            "8. (Don't Fear) The Reaper\n",
            "9. (I've Had) The Time of My Life\n",
            "10. (Let's Have A) Party\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    # Debug: Print the user ID before encoding\n",
        "    print(f\"Original user ID: {user_id}\")\n",
        "    \n",
        "    # Attempt transformation\n",
        "    encoded_user_id = preprocessor.user_id_encoder.transform([user_id])\n",
        "    print(f\"Encoded user ID: {encoded_user_id}\")\n",
        "    \n",
        "    # Check if the encoded user ID exists in the encoder's classes\n",
        "    if encoded_user_id[0] not in preprocessor.user_id_encoder.classes_:\n",
        "        print(f\"Encoded user ID {encoded_user_id} not found in encoder. Handling as OOV...\")\n",
        "        # Handle OOV user (e.g., assign default ID)\n",
        "        encoded_user_id = [preprocessor.user_id_encoder.classes_.shape[0] - 1]\n",
        "        print(f\"Assigned Default ID for OOV User: {encoded_user_id}\")\n",
        "    \n",
        "    recommended_items = get_recommendations(\n",
        "        model=model,\n",
        "        user_id=user_id,  # Pass original user ID for logging clarity\n",
        "        # encoded_user_id=encoded_user_id,  // Removed this line\n",
        "        data_encoded=data_encoded,\n",
        "        user_id_encoder=preprocessor.user_id_encoder,\n",
        "        artist_encoder=preprocessor.artist_encoder,\n",
        "        track_encoder=preprocessor.track_encoder,\n",
        "        genre_encoder=preprocessor.genre_encoder,\n",
        "        music_id_to_info=music_id_to_info,  # Ensure this is defined\n",
        "        device=device,\n",
        "        top_k=top_k\n",
        "    )\n",
        "    print(f\"Top {top_k} recommendations for user {user_id}:\")\n",
        "    for idx, item in enumerate(recommended_items, start=1):\n",
        "        print(f\"{idx}. {item[0]} by {item[1]}\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Sample Predictions for Users\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ReNeLLM",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.20"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
