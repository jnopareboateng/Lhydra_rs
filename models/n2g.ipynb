{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/name_gender.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>gender</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aaban</td>\n",
       "      <td>M</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aabha</td>\n",
       "      <td>F</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aabid</td>\n",
       "      <td>M</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aabriella</td>\n",
       "      <td>F</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aada</td>\n",
       "      <td>F</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        name gender  prob\n",
       "0      Aaban      M   1.0\n",
       "1      Aabha      F   1.0\n",
       "2      Aabid      M   1.0\n",
       "3  Aabriella      F   1.0\n",
       "4       Aada      F   1.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df[\"name\"]\n",
    "labels = df[\"gender\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (76020,)\n",
      "X_test shape: (19005,)\n",
      "y_train shape: (76020,)\n",
      "y_test shape: (19005,)\n"
     ]
    }
   ],
   "source": [
    "# Preprocess and split your data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, labels, test_size=0.2, random_state=42\n",
    ")\n",
    "print(\n",
    "    f\"X_train shape: {X_train.shape}\\nX_test shape: {X_test.shape}\\ny_train shape: {y_train.shape}\\ny_test shape: {y_test.shape}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "y_train_encoded = le.fit_transform(y_train)\n",
    "y_test_encoded = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction\n",
    "vectorizer = CountVectorizer(analyzer=\"char\", ngram_range=(1, 3))\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "models = {\n",
    "    # \"Naive Bayes\": MultinomialNB(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    # \"SVR\": SVC(kernel=\"linear\", probability=True),  # Since we're doing classification\n",
    "    # \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for shape mismatch\n",
    "assert X_train_vectorized.shape[0] == len(y_train_encoded), \"Mismatched sample sizes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.8242567745330176\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate models\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_vectorized, y_train_encoded)\n",
    "    scores = cross_val_score(model, X_test_vectorized, y_test_encoded, cv=5)\n",
    "    print(f\"{name} Accuracy: {scores.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Assuming 'model' is your trained model\n",
    "with open('model.pkl', 'wb') as file:\n",
    "    pickle.dump(model, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model.pkl', 'rb') as file:\n",
    "    loaded_model = pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35001, 32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../data/dataset.csv\")\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender\n",
       "Male       18095\n",
       "Female     16906\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'age', 'education', 'gender', 'name', 'country', 'music',\n",
       "       'artist_name', 'featured_artists', 'genre', 'plays',\n",
       "       'artiste_popularity', 'audio_popularity', 'music_acousticness',\n",
       "       'danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness',\n",
       "       'instrumentalness', 'liveness', 'valence', 'tempo', 'time_signature',\n",
       "       'track_genre', 'release_date', 'explicit', 'duration', 'music_id',\n",
       "       'id_artists', 'followers'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rename Male to M and Female to F\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Danielle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mloaded_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mname\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/venv_310/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:904\u001b[0m, in \u001b[0;36mForestClassifier.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    884\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    885\u001b[0m \u001b[38;5;124;03m    Predict class for X.\u001b[39;00m\n\u001b[1;32m    886\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;124;03m        The predicted classes.\u001b[39;00m\n\u001b[1;32m    903\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 904\u001b[0m     proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    906\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    907\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mtake(np\u001b[38;5;241m.\u001b[39margmax(proba, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/venv_310/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:946\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    944\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    945\u001b[0m \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[0;32m--> 946\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_X_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;66;03m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[1;32m    949\u001b[0m n_jobs, _, _ \u001b[38;5;241m=\u001b[39m _partition_estimators(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n",
      "File \u001b[0;32m~/anaconda3/envs/venv_310/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:641\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    639\u001b[0m     force_all_finite \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 641\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    642\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    643\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    644\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    645\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    646\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    647\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    648\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (X\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc \u001b[38;5;129;01mor\u001b[39;00m X\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc):\n\u001b[1;32m    649\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/venv_310/lib/python3.10/site-packages/sklearn/base.py:633\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    631\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 633\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[1;32m    635\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[0;32m~/anaconda3/envs/venv_310/lib/python3.10/site-packages/sklearn/utils/validation.py:1007\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1005\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1006\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1007\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1008\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[1;32m   1009\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1010\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[1;32m   1011\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/venv_310/lib/python3.10/site-packages/sklearn/utils/_array_api.py:746\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[1;32m    744\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    745\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 746\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[1;32m    749\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[1;32m    750\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "File \u001b[0;32m~/anaconda3/envs/venv_310/lib/python3.10/site-packages/pandas/core/series.py:1031\u001b[0m, in \u001b[0;36mSeries.__array__\u001b[0;34m(self, dtype, copy)\u001b[0m\n\u001b[1;32m    981\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    982\u001b[0m \u001b[38;5;124;03mReturn the values as a NumPy array.\u001b[39;00m\n\u001b[1;32m    983\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[38;5;124;03m      dtype='datetime64[ns]')\u001b[39;00m\n\u001b[1;32m   1029\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1030\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m-> 1031\u001b[0m arr \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1032\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m using_copy_on_write() \u001b[38;5;129;01mand\u001b[39;00m astype_is_view(values\u001b[38;5;241m.\u001b[39mdtype, arr\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[1;32m   1033\u001b[0m     arr \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mview()\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Danielle'"
     ]
    }
   ],
   "source": [
    "predictions = loaded_model.predict(data['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# # Define the parameter grid for each model\n",
    "# param_grid_nb = {\"alpha\": [0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "# param_grid_rf = {\n",
    "#     \"n_estimators\": [10, 50, 100, 200],\n",
    "#     \"max_depth\": [None, 10, 20, 30],\n",
    "#     \"min_samples_split\": [2, 5, 10],\n",
    "#     \"min_samples_leaf\": [1, 2, 4],\n",
    "#     \"max_features\": [\"sqrt\", \"log2\"],\n",
    "# }\n",
    "\n",
    "# param_grid_svc = {\n",
    "#     \"C\": [0.1, 1, 10, 100],\n",
    "#     \"gamma\": [\"scale\", \"auto\"],\n",
    "#     \"kernel\": [\"linear\", \"rbf\", \"poly\"],\n",
    "# }\n",
    "\n",
    "# param_grid_gb = {\n",
    "#     \"n_estimators\": [100, 200, 300],\n",
    "#     \"learning_rate\": [0.01, 0.1, 0.2],\n",
    "#     \"max_depth\": [3, 4, 5],\n",
    "# }\n",
    "\n",
    "# # Initialize RandomizedSearchCV for each model\n",
    "# random_search_cv_nb = RandomizedSearchCV(\n",
    "#     MultinomialNB(), param_grid_nb, cv=5, scoring=\"accuracy\"\n",
    "# )\n",
    "# random_search_cv_rf = RandomizedSearchCV(\n",
    "#     RandomForestClassifier(), param_grid_rf, cv=5, scoring=\"accuracy\"\n",
    "# )\n",
    "# random_search_cv_svc = RandomizedSearchCV(\n",
    "#     SVC(), param_grid_svc, cv=5, scoring=\"accuracy\"\n",
    "# )\n",
    "# random_search_cv_gb = RandomizedSearchCV(\n",
    "#     GradientBoostingClassifier(), param_grid_gb, cv=5, scoring=\"accuracy\"\n",
    "# )\n",
    "\n",
    "# # Perform hyperparameter tuning and fit the models\n",
    "# random_search_cv_nb.fit(X_train_vectorized, y_train_encoded)\n",
    "# random_search_cv_rf.fit(X_train_vectorized, y_train_encoded)\n",
    "# random_search_cv_svc.fit(X_train_vectorized, y_train_encoded)\n",
    "# random_search_cv_gb.fit(X_train_vectorized, y_train_encoded)\n",
    "\n",
    "# # Get the best parameters and the best score for each model\n",
    "# best_params_nb = random_search_cv_nb.best_params_\n",
    "# best_score_nb = random_search_cv_nb.best_score_\n",
    "\n",
    "# best_params_rf = random_search_cv_rf.best_params_\n",
    "# best_score_rf = random_search_cv_rf.best_score_\n",
    "\n",
    "# best_params_svc = random_search_cv_svc.best_params_\n",
    "# best_score_svc = random_search_cv_svc.best_score_\n",
    "\n",
    "# best_params_gb = random_search_cv_gb.best_params_\n",
    "# best_score_gb = random_search_cv_gb.best_score_\n",
    "\n",
    "# # Print the best parameters and the best score for each model\n",
    "# print(f\"Naive Bayes Best Params: {best_params_nb}, Best Score: {best_score_nb}\")\n",
    "# print(f\"Random Forest Best Params: {best_params_rf}, Best Score: {best_score_rf}\")\n",
    "# print(f\"SVC Best Params: {best_params_svc}, Best Score: {best_score_svc}\")\n",
    "# print(f\"Gradient Boosting Best Params: {best_params_gb}, Best Score: {best_score_gb}\")\n",
    "\n",
    "# # Use the best estimator for further predictions\n",
    "# best_model_nb = random_search_cv_nb.best_estimator_\n",
    "# best_model_rf = random_search_cv_rf.best_estimator_\n",
    "# best_model_svc = random_search_cv_svc.best_estimator_\n",
    "# best_model_gb = random_search_cv_gb.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on new data using the trained SVC model\n",
    "new_features = data[\"name\"]\n",
    "new_features_vectorized = vectorizer.transform(new_features)\n",
    "new_predictions_encoded = model.predict(new_features_vectorized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode the predictions back to the original labels\n",
    "new_predictions = le.inverse_transform(new_predictions_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "# Replace existing gender column with newly predicted one\n",
    "data[\"gender\"] = new_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender\n",
       "F    17524\n",
       "M    17477\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"gender\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"../data/dataset_v2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>gender</th>\n",
       "      <th>name</th>\n",
       "      <th>country</th>\n",
       "      <th>music</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>featured_artists</th>\n",
       "      <th>genre</th>\n",
       "      <th>...</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>track_genre</th>\n",
       "      <th>release_date</th>\n",
       "      <th>explicit</th>\n",
       "      <th>duration</th>\n",
       "      <th>music_id</th>\n",
       "      <th>id_artists</th>\n",
       "      <th>followers</th>\n",
       "      <th>ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>83811</td>\n",
       "      <td>16</td>\n",
       "      <td>Undergraduate</td>\n",
       "      <td>F</td>\n",
       "      <td>Danielle</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Bank Account</td>\n",
       "      <td>21 Savage</td>\n",
       "      <td>Birdy, Zoé</td>\n",
       "      <td>Dark Trap</td>\n",
       "      <td>...</td>\n",
       "      <td>147.482666</td>\n",
       "      <td>5</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2017-09-23</td>\n",
       "      <td>True</td>\n",
       "      <td>3.67</td>\n",
       "      <td>2fQrGHiQOvpL9UgPvtYy6G</td>\n",
       "      <td>spotify:artist:1URnnhqYAYcrqrcwql10ft</td>\n",
       "      <td>440898</td>\n",
       "      <td>1.979877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>83811</td>\n",
       "      <td>16</td>\n",
       "      <td>Undergraduate</td>\n",
       "      <td>F</td>\n",
       "      <td>Danielle</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Mo Money Mo Problems (feat. Mase &amp; Puff Daddy)...</td>\n",
       "      <td>The Notorious B.I.G.</td>\n",
       "      <td>LUDMILLA</td>\n",
       "      <td>Underground Rap</td>\n",
       "      <td>...</td>\n",
       "      <td>104.536000</td>\n",
       "      <td>4</td>\n",
       "      <td>hardcore</td>\n",
       "      <td>1997-03-04</td>\n",
       "      <td>False</td>\n",
       "      <td>4.29</td>\n",
       "      <td>4INDiWSKvqSKDEu7mh8HFz</td>\n",
       "      <td>spotify:artist:5me0Irg2ANcsgc93uaYrpb</td>\n",
       "      <td>849749</td>\n",
       "      <td>4.446776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>83811</td>\n",
       "      <td>16</td>\n",
       "      <td>Undergraduate</td>\n",
       "      <td>F</td>\n",
       "      <td>Danielle</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Little Talks</td>\n",
       "      <td>Of Monsters and Men</td>\n",
       "      <td>Ninho, Snoop Dogg, Russ, Paramore</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>102.961000</td>\n",
       "      <td>4</td>\n",
       "      <td>folk</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>True</td>\n",
       "      <td>4.44</td>\n",
       "      <td>2ihCaVdNZmnHZWt0fvAM7B</td>\n",
       "      <td>spotify:artist:4dwdTW1Lfiq0cM8nBAqIIz</td>\n",
       "      <td>733052</td>\n",
       "      <td>4.193334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13397</td>\n",
       "      <td>17</td>\n",
       "      <td>Middle School</td>\n",
       "      <td>M</td>\n",
       "      <td>Angel</td>\n",
       "      <td>Non-Urban</td>\n",
       "      <td>Wherever I Go</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>Keith Urban, DJ Khaled, NIKI, MF DOOM</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>99.961000</td>\n",
       "      <td>4</td>\n",
       "      <td>piano</td>\n",
       "      <td>2016-12-02</td>\n",
       "      <td>True</td>\n",
       "      <td>2.83</td>\n",
       "      <td>46jLy47W8rkf8rEX04gMKB</td>\n",
       "      <td>spotify:artist:5Pwc4xIPtQLFEnJriah9YJ</td>\n",
       "      <td>766179</td>\n",
       "      <td>3.311571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13397</td>\n",
       "      <td>17</td>\n",
       "      <td>Middle School</td>\n",
       "      <td>M</td>\n",
       "      <td>Angel</td>\n",
       "      <td>Non-Urban</td>\n",
       "      <td>Hands To Myself</td>\n",
       "      <td>Selena Gomez</td>\n",
       "      <td>SAINt JHN, David Bisbal, will.i.am</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>84.918633</td>\n",
       "      <td>3</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2015-10-09</td>\n",
       "      <td>True</td>\n",
       "      <td>3.34</td>\n",
       "      <td>3CJvmtWw2bJsudbAC5uCQk</td>\n",
       "      <td>spotify:artist:0C8ZW7ezQVs4URX5aX7Kqx</td>\n",
       "      <td>399591</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  age        education gender      name      country  \\\n",
       "0    83811   16   Undergraduate       F  Danielle       Urban    \n",
       "1    83811   16   Undergraduate       F  Danielle       Urban    \n",
       "2    83811   16   Undergraduate       F  Danielle       Urban    \n",
       "3    13397   17   Middle School       M     Angel   Non-Urban    \n",
       "4    13397   17   Middle School       M     Angel   Non-Urban    \n",
       "\n",
       "                                               music           artist_name  \\\n",
       "0                                       Bank Account             21 Savage   \n",
       "1  Mo Money Mo Problems (feat. Mase & Puff Daddy)...  The Notorious B.I.G.   \n",
       "2                                       Little Talks   Of Monsters and Men   \n",
       "3                                      Wherever I Go           OneRepublic   \n",
       "4                                    Hands To Myself          Selena Gomez   \n",
       "\n",
       "                        featured_artists            genre  ...       tempo  \\\n",
       "0                             Birdy, Zoé        Dark Trap  ...  147.482666   \n",
       "1                               LUDMILLA  Underground Rap  ...  104.536000   \n",
       "2      Ninho, Snoop Dogg, Russ, Paramore          Unknown  ...  102.961000   \n",
       "3  Keith Urban, DJ Khaled, NIKI, MF DOOM          Unknown  ...   99.961000   \n",
       "4     SAINt JHN, David Bisbal, will.i.am          Unknown  ...   84.918633   \n",
       "\n",
       "   time_signature  track_genre  release_date  explicit  duration  \\\n",
       "0               5      Unknown    2017-09-23      True      3.67   \n",
       "1               4     hardcore    1997-03-04     False      4.29   \n",
       "2               4         folk    2012-01-01      True      4.44   \n",
       "3               4        piano    2016-12-02      True      2.83   \n",
       "4               3      Unknown    2015-10-09      True      3.34   \n",
       "\n",
       "                 music_id                             id_artists  followers  \\\n",
       "0  2fQrGHiQOvpL9UgPvtYy6G  spotify:artist:1URnnhqYAYcrqrcwql10ft     440898   \n",
       "1  4INDiWSKvqSKDEu7mh8HFz  spotify:artist:5me0Irg2ANcsgc93uaYrpb     849749   \n",
       "2  2ihCaVdNZmnHZWt0fvAM7B  spotify:artist:4dwdTW1Lfiq0cM8nBAqIIz     733052   \n",
       "3  46jLy47W8rkf8rEX04gMKB  spotify:artist:5Pwc4xIPtQLFEnJriah9YJ     766179   \n",
       "4  3CJvmtWw2bJsudbAC5uCQk  spotify:artist:0C8ZW7ezQVs4URX5aX7Kqx     399591   \n",
       "\n",
       "    ratings  \n",
       "0  1.979877  \n",
       "1  4.446776  \n",
       "2  4.193334  \n",
       "3  3.311571  \n",
       "4  1.000000  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the updated DataFrame to a new CSV file\n",
    "# new_df.to_csv(\"data/new_dataset.csv\", index=False)\n",
    "# Print out the first few rows to verify\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('data/dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Apply a log transformation to reduce skewness in the 'plays' column\n",
    "# df[\"log_plays\"] = np.log1p(df[\"plays\"])\n",
    "# # Initialize the MinMaxScaler to scale between 1 and 5\n",
    "# scaler = MinMaxScaler(feature_range=(1, 5))\n",
    "\n",
    "# # Fit and transform the 'log_plays' data\n",
    "# df[\"ratings\"] = scaler.fit_transform(df[[\"log_plays\"]])\n",
    "\n",
    "# # Drop the 'log_plays' column as it's no longer needed\n",
    "# df.drop(\"log_plays\", axis=1, inplace=True)\n",
    "\n",
    "# # Handle missing values\n",
    "# df[\"featured_artists\"] = df[\"featured_artists\"].fillna(\"None\")\n",
    "# df[\"genre\"] = df[\"genre\"].fillna(\"Unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"data/music_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
