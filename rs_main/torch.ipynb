{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import torch\n",
    "torch.cuda.is_available()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/cleaned_modv2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['user_id'] = df['user_id'].astype('category')\n",
    "df['time_signature'] = df['time_signature'].astype(int)\n",
    "df['explicit'] = df['explicit'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>music</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>featured_artists</th>\n",
       "      <th>genre</th>\n",
       "      <th>plays</th>\n",
       "      <th>duration</th>\n",
       "      <th>music_id</th>\n",
       "      <th>...</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>explicit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>83811</td>\n",
       "      <td>16</td>\n",
       "      <td>F</td>\n",
       "      <td>Bank Account</td>\n",
       "      <td>21 Savage</td>\n",
       "      <td>Birdy, Zoé</td>\n",
       "      <td>Dark Trap</td>\n",
       "      <td>11</td>\n",
       "      <td>3.67</td>\n",
       "      <td>2fQrGHiQOvpL9UgPvtYy6G</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-8.228</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3510</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.0871</td>\n",
       "      <td>0.376</td>\n",
       "      <td>75.0160</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>83811</td>\n",
       "      <td>16</td>\n",
       "      <td>F</td>\n",
       "      <td>Little Talks</td>\n",
       "      <td>Of Monsters and Men</td>\n",
       "      <td>Ninho, Snoop Dogg, Russ, Paramore</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>686</td>\n",
       "      <td>4.44</td>\n",
       "      <td>2ihCaVdNZmnHZWt0fvAM7B</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-7.879</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0322</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2845</td>\n",
       "      <td>0.413</td>\n",
       "      <td>101.8905</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  user_id  age gender         music          artist_name  \\\n",
       "0   83811   16      F  Bank Account            21 Savage   \n",
       "1   83811   16      F  Little Talks  Of Monsters and Men   \n",
       "\n",
       "                    featured_artists      genre  plays  duration  \\\n",
       "0                         Birdy, Zoé  Dark Trap     11      3.67   \n",
       "1  Ninho, Snoop Dogg, Russ, Paramore    Unknown    686      4.44   \n",
       "\n",
       "                 music_id  ...  key  loudness  mode  speechiness  \\\n",
       "0  2fQrGHiQOvpL9UgPvtYy6G  ...  8.0    -8.228   0.0       0.3510   \n",
       "1  2ihCaVdNZmnHZWt0fvAM7B  ...  1.0    -7.879   1.0       0.0322   \n",
       "\n",
       "   instrumentalness  liveness  valence     tempo  time_signature  explicit  \n",
       "0          0.000007    0.0871    0.376   75.0160               4         1  \n",
       "1          0.000000    0.2845    0.413  101.8905               4         0  \n",
       "\n",
       "[2 rows x 24 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19974 entries, 0 to 19973\n",
      "Data columns (total 24 columns):\n",
      " #   Column            Non-Null Count  Dtype   \n",
      "---  ------            --------------  -----   \n",
      " 0   user_id           19974 non-null  category\n",
      " 1   age               19974 non-null  int64   \n",
      " 2   gender            19974 non-null  object  \n",
      " 3   music             19974 non-null  object  \n",
      " 4   artist_name       19974 non-null  object  \n",
      " 5   featured_artists  19974 non-null  object  \n",
      " 6   genre             19974 non-null  object  \n",
      " 7   plays             19974 non-null  int64   \n",
      " 8   duration          19974 non-null  float64 \n",
      " 9   music_id          19974 non-null  object  \n",
      " 10  id_artists        19974 non-null  object  \n",
      " 11  acousticness      19974 non-null  float64 \n",
      " 12  danceability      19974 non-null  float64 \n",
      " 13  energy            19974 non-null  float64 \n",
      " 14  key               19974 non-null  float64 \n",
      " 15  loudness          19974 non-null  float64 \n",
      " 16  mode              19974 non-null  float64 \n",
      " 17  speechiness       19974 non-null  float64 \n",
      " 18  instrumentalness  19974 non-null  float64 \n",
      " 19  liveness          19974 non-null  float64 \n",
      " 20  valence           19974 non-null  float64 \n",
      " 21  tempo             19974 non-null  float64 \n",
      " 22  time_signature    19974 non-null  int64   \n",
      " 23  explicit          19974 non-null  int64   \n",
      "dtypes: category(1), float64(12), int64(4), object(7)\n",
      "memory usage: 3.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>plays</th>\n",
       "      <th>duration</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>explicit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0.015100</td>\n",
       "      <td>0.884000</td>\n",
       "      <td>0.346000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-8.228000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.351000</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.087100</td>\n",
       "      <td>0.376000</td>\n",
       "      <td>75.016000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>686</td>\n",
       "      <td>4.44</td>\n",
       "      <td>0.180850</td>\n",
       "      <td>0.577500</td>\n",
       "      <td>0.497500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-7.879000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.032200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.284500</td>\n",
       "      <td>0.413000</td>\n",
       "      <td>101.890500</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>136</td>\n",
       "      <td>2.83</td>\n",
       "      <td>0.363482</td>\n",
       "      <td>0.568667</td>\n",
       "      <td>0.644000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-7.344833</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.089400</td>\n",
       "      <td>0.043432</td>\n",
       "      <td>0.273133</td>\n",
       "      <td>0.404183</td>\n",
       "      <td>120.850500</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>230</td>\n",
       "      <td>5.14</td>\n",
       "      <td>0.676000</td>\n",
       "      <td>0.843000</td>\n",
       "      <td>0.419000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-7.606000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.167000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.096600</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>109.283000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44</td>\n",
       "      <td>391</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.359471</td>\n",
       "      <td>0.518229</td>\n",
       "      <td>0.544046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.894632</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.078837</td>\n",
       "      <td>0.235527</td>\n",
       "      <td>0.180354</td>\n",
       "      <td>0.380815</td>\n",
       "      <td>120.488479</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19969</th>\n",
       "      <td>18</td>\n",
       "      <td>890</td>\n",
       "      <td>4.03</td>\n",
       "      <td>0.752000</td>\n",
       "      <td>0.528000</td>\n",
       "      <td>0.355000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-11.712000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.046400</td>\n",
       "      <td>0.091100</td>\n",
       "      <td>0.427000</td>\n",
       "      <td>0.677000</td>\n",
       "      <td>123.014000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19970</th>\n",
       "      <td>18</td>\n",
       "      <td>746</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.849000</td>\n",
       "      <td>0.529000</td>\n",
       "      <td>0.112000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-13.413000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033800</td>\n",
       "      <td>0.005650</td>\n",
       "      <td>0.095200</td>\n",
       "      <td>0.211000</td>\n",
       "      <td>79.858000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19971</th>\n",
       "      <td>44</td>\n",
       "      <td>176</td>\n",
       "      <td>4.10</td>\n",
       "      <td>0.221401</td>\n",
       "      <td>0.579714</td>\n",
       "      <td>0.724286</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.716571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.058614</td>\n",
       "      <td>0.003260</td>\n",
       "      <td>0.156643</td>\n",
       "      <td>0.567000</td>\n",
       "      <td>113.667714</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19972</th>\n",
       "      <td>65</td>\n",
       "      <td>394</td>\n",
       "      <td>3.93</td>\n",
       "      <td>0.079100</td>\n",
       "      <td>0.506000</td>\n",
       "      <td>0.799000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.580000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.092900</td>\n",
       "      <td>0.461000</td>\n",
       "      <td>120.405000</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19973</th>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>3.11</td>\n",
       "      <td>0.333422</td>\n",
       "      <td>0.550200</td>\n",
       "      <td>0.577300</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-8.730700</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.057460</td>\n",
       "      <td>0.106721</td>\n",
       "      <td>0.176250</td>\n",
       "      <td>0.436270</td>\n",
       "      <td>131.094800</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19974 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  plays  duration  acousticness  danceability    energy  key  \\\n",
       "0       16     11      3.67      0.015100      0.884000  0.346000  8.0   \n",
       "1       16    686      4.44      0.180850      0.577500  0.497500  1.0   \n",
       "2       17    136      2.83      0.363482      0.568667  0.644000  0.0   \n",
       "3       44    230      5.14      0.676000      0.843000  0.419000  1.0   \n",
       "4       44    391      3.20      0.359471      0.518229  0.544046  0.0   \n",
       "...    ...    ...       ...           ...           ...       ...  ...   \n",
       "19969   18    890      4.03      0.752000      0.528000  0.355000  9.0   \n",
       "19970   18    746      3.26      0.849000      0.529000  0.112000  9.0   \n",
       "19971   44    176      4.10      0.221401      0.579714  0.724286  1.0   \n",
       "19972   65    394      3.93      0.079100      0.506000  0.799000  1.0   \n",
       "19973   65      1      3.11      0.333422      0.550200  0.577300  8.0   \n",
       "\n",
       "        loudness  mode  speechiness  instrumentalness  liveness   valence  \\\n",
       "0      -8.228000   0.0     0.351000          0.000007  0.087100  0.376000   \n",
       "1      -7.879000   1.0     0.032200          0.000000  0.284500  0.413000   \n",
       "2      -7.344833   1.0     0.089400          0.043432  0.273133  0.404183   \n",
       "3      -7.606000   1.0     0.167000          0.000000  0.096600  0.400000   \n",
       "4      -9.894632   1.0     0.078837          0.235527  0.180354  0.380815   \n",
       "...          ...   ...          ...               ...       ...       ...   \n",
       "19969 -11.712000   1.0     0.046400          0.091100  0.427000  0.677000   \n",
       "19970 -13.413000   0.0     0.033800          0.005650  0.095200  0.211000   \n",
       "19971  -6.716571   1.0     0.058614          0.003260  0.156643  0.567000   \n",
       "19972  -6.580000   1.0     0.380000          0.000000  0.092900  0.461000   \n",
       "19973  -8.730700   1.0     0.057460          0.106721  0.176250  0.436270   \n",
       "\n",
       "            tempo  time_signature  explicit  \n",
       "0       75.016000               4         1  \n",
       "1      101.890500               4         0  \n",
       "2      120.850500               4         0  \n",
       "3      109.283000               4         0  \n",
       "4      120.488479               4         0  \n",
       "...           ...             ...       ...  \n",
       "19969  123.014000               4         0  \n",
       "19970   79.858000               4         0  \n",
       "19971  113.667714               4         0  \n",
       "19972  120.405000               5         1  \n",
       "19973  131.094800               4         0  \n",
       "\n",
       "[19974 rows x 16 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_features = df.select_dtypes(include=[np.number])\n",
    "numerical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>music</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>featured_artists</th>\n",
       "      <th>genre</th>\n",
       "      <th>music_id</th>\n",
       "      <th>id_artists</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F</td>\n",
       "      <td>Bank Account</td>\n",
       "      <td>21 Savage</td>\n",
       "      <td>Birdy, Zoé</td>\n",
       "      <td>Dark Trap</td>\n",
       "      <td>2fQrGHiQOvpL9UgPvtYy6G</td>\n",
       "      <td>spotify:artist:1URnnhqYAYcrqrcwql10ft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F</td>\n",
       "      <td>Little Talks</td>\n",
       "      <td>Of Monsters and Men</td>\n",
       "      <td>Ninho, Snoop Dogg, Russ, Paramore</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2ihCaVdNZmnHZWt0fvAM7B</td>\n",
       "      <td>spotify:artist:4dwdTW1Lfiq0cM8nBAqIIz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>Wherever I Go</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>Keith Urban, DJ Khaled, NIKI, MF DOOM</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>46jLy47W8rkf8rEX04gMKB</td>\n",
       "      <td>spotify:artist:5Pwc4xIPtQLFEnJriah9YJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>No New Friends</td>\n",
       "      <td>DJ Khaled</td>\n",
       "      <td>The xx, LIT killah</td>\n",
       "      <td>Pop</td>\n",
       "      <td>5oVlbbiKGdGeZkWCFy0mqk</td>\n",
       "      <td>spotify:artist:0QHgL1lAIqAw0HtD7YldmP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>Dreams</td>\n",
       "      <td>Campsite Dream</td>\n",
       "      <td>none</td>\n",
       "      <td>Country</td>\n",
       "      <td>1SNoSoQ3JZldOhzBY9gw0n</td>\n",
       "      <td>spotify:artist:69VkQLf4DH7GJ68BCDOPKL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19969</th>\n",
       "      <td>F</td>\n",
       "      <td>Houses Of The Holy</td>\n",
       "      <td>Led Zeppelin</td>\n",
       "      <td>Dido, Van Halen, Bazzi, Years &amp; Years, Bibi Bl...</td>\n",
       "      <td>Dance/Electronic</td>\n",
       "      <td>4es5wreov9D4Y4fXLGZkuB</td>\n",
       "      <td>spotify:artist:36QJpDe2go2KgaRleHCDTp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19970</th>\n",
       "      <td>F</td>\n",
       "      <td>Halfway Gone</td>\n",
       "      <td>Lifehouse</td>\n",
       "      <td>none</td>\n",
       "      <td>Rock</td>\n",
       "      <td>7JtQLJcOyVJKUPdUC4lggE</td>\n",
       "      <td>spotify:artist:5PokPZn11xzZXyXSfnvIM3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19971</th>\n",
       "      <td>M</td>\n",
       "      <td>Take You Down</td>\n",
       "      <td>Chris Brown</td>\n",
       "      <td>Florida Georgia Line</td>\n",
       "      <td>Rock</td>\n",
       "      <td>3wu9ADop1FXdhToPCxwBL8</td>\n",
       "      <td>spotify:artist:7bXgB6jMjp9ATFy66eO08Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19972</th>\n",
       "      <td>F</td>\n",
       "      <td>We Fly High</td>\n",
       "      <td>Jim Jones</td>\n",
       "      <td>none</td>\n",
       "      <td>Christian/Gospel</td>\n",
       "      <td>5rXkgeY6rpcHcsolCpXZHR</td>\n",
       "      <td>spotify:artist:6AMa1VFQ7qCi61tCRtVWXe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19973</th>\n",
       "      <td>F</td>\n",
       "      <td>Radioactive</td>\n",
       "      <td>Imagine Dragons</td>\n",
       "      <td>Boyce Avenue, Dermot Kennedy, Kelly Rowland</td>\n",
       "      <td>Christian/Gospel</td>\n",
       "      <td>6Ep6BzIOB9tz3P4sWqiiAB</td>\n",
       "      <td>spotify:artist:53XhwfbYqKCa1cC15pYq2q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19974 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender               music          artist_name  \\\n",
       "0          F        Bank Account            21 Savage   \n",
       "1          F        Little Talks  Of Monsters and Men   \n",
       "2          M       Wherever I Go          OneRepublic   \n",
       "3          M      No New Friends            DJ Khaled   \n",
       "4          M              Dreams       Campsite Dream   \n",
       "...      ...                 ...                  ...   \n",
       "19969      F  Houses Of The Holy         Led Zeppelin   \n",
       "19970      F        Halfway Gone            Lifehouse   \n",
       "19971      M       Take You Down          Chris Brown   \n",
       "19972      F         We Fly High            Jim Jones   \n",
       "19973      F         Radioactive      Imagine Dragons   \n",
       "\n",
       "                                        featured_artists             genre  \\\n",
       "0                                             Birdy, Zoé         Dark Trap   \n",
       "1                      Ninho, Snoop Dogg, Russ, Paramore           Unknown   \n",
       "2                  Keith Urban, DJ Khaled, NIKI, MF DOOM           Unknown   \n",
       "3                                     The xx, LIT killah               Pop   \n",
       "4                                                   none           Country   \n",
       "...                                                  ...               ...   \n",
       "19969  Dido, Van Halen, Bazzi, Years & Years, Bibi Bl...  Dance/Electronic   \n",
       "19970                                               none              Rock   \n",
       "19971                               Florida Georgia Line              Rock   \n",
       "19972                                               none  Christian/Gospel   \n",
       "19973        Boyce Avenue, Dermot Kennedy, Kelly Rowland  Christian/Gospel   \n",
       "\n",
       "                     music_id                             id_artists  \n",
       "0      2fQrGHiQOvpL9UgPvtYy6G  spotify:artist:1URnnhqYAYcrqrcwql10ft  \n",
       "1      2ihCaVdNZmnHZWt0fvAM7B  spotify:artist:4dwdTW1Lfiq0cM8nBAqIIz  \n",
       "2      46jLy47W8rkf8rEX04gMKB  spotify:artist:5Pwc4xIPtQLFEnJriah9YJ  \n",
       "3      5oVlbbiKGdGeZkWCFy0mqk  spotify:artist:0QHgL1lAIqAw0HtD7YldmP  \n",
       "4      1SNoSoQ3JZldOhzBY9gw0n  spotify:artist:69VkQLf4DH7GJ68BCDOPKL  \n",
       "...                       ...                                    ...  \n",
       "19969  4es5wreov9D4Y4fXLGZkuB  spotify:artist:36QJpDe2go2KgaRleHCDTp  \n",
       "19970  7JtQLJcOyVJKUPdUC4lggE  spotify:artist:5PokPZn11xzZXyXSfnvIM3  \n",
       "19971  3wu9ADop1FXdhToPCxwBL8  spotify:artist:7bXgB6jMjp9ATFy66eO08Z  \n",
       "19972  5rXkgeY6rpcHcsolCpXZHR  spotify:artist:6AMa1VFQ7qCi61tCRtVWXe  \n",
       "19973  6Ep6BzIOB9tz3P4sWqiiAB  spotify:artist:53XhwfbYqKCa1cC15pYq2q  \n",
       "\n",
       "[19974 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_features = df.select_dtypes(include=[object])\n",
    "categorical_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare user features\n",
    "user_features = ['user_id', 'age', 'gender']\n",
    "user_features_mapped = pd.get_dummies(data[user_features], columns=['gender'])\n",
    "\n",
    "# Prepare item features\n",
    "item_features = ['music_id', 'artist_name', 'genre']\n",
    "item_features_mapped = pd.get_dummies(data[item_features], columns=['genre'])\n",
    "\n",
    "# Prepare audio features\n",
    "audio_features = ['acousticness', 'danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', \n",
    "                  'instrumentalness', 'liveness', 'valence', 'tempo', 'time_signature', 'explicit']\n",
    "audio_features_scaled = (data[audio_features] - data[audio_features].mean()) / data[audio_features].std()\n",
    "\n",
    "# Combine user, item, and audio features\n",
    "features = pd.concat([user_features_mapped, item_features_mapped, audio_features_scaled], axis=1)\n",
    "\n",
    "# Prepare target variable\n",
    "target = data['plays']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "train_data = features.sample(frac=0.8, random_state=42)\n",
    "test_data = features.drop(train_data.index)\n",
    "\n",
    "train_target = target[train_data.index]\n",
    "test_target = target[test_data.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19974 entries, 0 to 19973\n",
      "Data columns (total 24 columns):\n",
      " #   Column            Non-Null Count  Dtype   \n",
      "---  ------            --------------  -----   \n",
      " 0   user_id           19974 non-null  category\n",
      " 1   age               19974 non-null  int64   \n",
      " 2   gender            19974 non-null  object  \n",
      " 3   music             19974 non-null  object  \n",
      " 4   artist_name       19974 non-null  object  \n",
      " 5   featured_artists  19974 non-null  object  \n",
      " 6   genre             19974 non-null  object  \n",
      " 7   plays             19974 non-null  int64   \n",
      " 8   duration          19974 non-null  float64 \n",
      " 9   music_id          19974 non-null  object  \n",
      " 10  id_artists        19974 non-null  object  \n",
      " 11  acousticness      19974 non-null  float64 \n",
      " 12  danceability      19974 non-null  float64 \n",
      " 13  energy            19974 non-null  float64 \n",
      " 14  key               19974 non-null  float64 \n",
      " 15  loudness          19974 non-null  float64 \n",
      " 16  mode              19974 non-null  float64 \n",
      " 17  speechiness       19974 non-null  float64 \n",
      " 18  instrumentalness  19974 non-null  float64 \n",
      " 19  liveness          19974 non-null  float64 \n",
      " 20  valence           19974 non-null  float64 \n",
      " 21  tempo             19974 non-null  float64 \n",
      " 22  time_signature    19974 non-null  int64   \n",
      " 23  explicit          19974 non-null  int64   \n",
      "dtypes: category(1), float64(12), int64(4), object(7)\n",
      "memory usage: 3.9+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert from object to category\n",
    "objects = data.select_dtypes(include=[object])\n",
    "for column in objects:\n",
    "    data[column] = data[column].astype('category')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Assuming your DataFrame is named 'data'\n",
    "\n",
    "# Perform label encoding for 'user_id' and 'music_id' columns\n",
    "user_id_encoder = LabelEncoder()\n",
    "music_id_encoder = LabelEncoder()\n",
    "data['user_id_encoded'] = user_id_encoder.fit_transform(data['user_id'])\n",
    "data['music_id_encoded'] = music_id_encoder.fit_transform(data['music_id'])\n",
    "\n",
    "# Perform label encoding for 'gender' column\n",
    "gender_encoder = LabelEncoder()\n",
    "data['gender_encoded'] = gender_encoder.fit_transform(data['gender'])\n",
    "\n",
    "# Perform TF-IDF encoding for 'artist_name' and 'genre' columns\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "artist_tfidf = tfidf_vectorizer.fit_transform(data['artist_name'])\n",
    "genre_tfidf = tfidf_vectorizer.fit_transform(data['genre'])\n",
    "\n",
    "# Convert TF-IDF matrices to DataFrames\n",
    "artist_tfidf_df = pd.DataFrame(artist_tfidf.toarray(), columns=[f'artist_tfidf_{i}' for i in range(artist_tfidf.shape[1])])\n",
    "genre_tfidf_df = pd.DataFrame(genre_tfidf.toarray(), columns=[f'genre_tfidf_{i}' for i in range(genre_tfidf.shape[1])])\n",
    "\n",
    "# Concatenate the encoded DataFrames with the original DataFrame\n",
    "data_encoded = pd.concat([data[['user_id_encoded', 'music_id_encoded', 'age', 'gender_encoded', 'duration', 'acousticness', 'danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'time_signature', 'explicit', 'plays']], artist_tfidf_df, genre_tfidf_df], axis=1)\n",
    "\n",
    "# Split the data into features and target\n",
    "features = data_encoded.drop(columns=['plays'])\n",
    "target = data_encoded['plays']\n",
    "\n",
    "# Split the data into train and test sets\n",
    "train_data = features.sample(frac=0.8, random_state=42)\n",
    "test_data = features.drop(train_data.index)\n",
    "\n",
    "train_target = target[train_data.index]\n",
    "test_target = target[test_data.index]\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "train_data = torch.tensor(train_data.values, dtype=torch.float)\n",
    "test_data = torch.tensor(test_data.values, dtype=torch.float)\n",
    "train_target = torch.tensor(train_target.values, dtype=torch.float).unsqueeze(1)\n",
    "test_target = torch.tensor(test_target.values, dtype=torch.float).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: torch.Size([15979, 6101])\n",
      "Test data shape: torch.Size([3995, 6101])\n",
      "Train target shape: torch.Size([15979, 1])\n",
      "Test target shape: torch.Size([3995, 1])\n"
     ]
    }
   ],
   "source": [
    "# verify the data \n",
    "print(f\"Train data shape: {train_data.shape}\\nTest data shape: {test_data.shape}\\nTrain target shape: {train_target.shape}\\nTest target shape: {test_target.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Loss: 0.2130\n",
      "Epoch [2/30], Loss: 0.1937\n",
      "Epoch [3/30], Loss: 0.1753\n",
      "Epoch [4/30], Loss: 0.1733\n",
      "Epoch [5/30], Loss: 0.1715\n",
      "Epoch [6/30], Loss: 0.1698\n",
      "Epoch [7/30], Loss: 0.1696\n",
      "Epoch [8/30], Loss: 0.1694\n",
      "Epoch [9/30], Loss: 0.1692\n",
      "Epoch [10/30], Loss: 0.1692\n",
      "Epoch [11/30], Loss: 0.1692\n",
      "Epoch [12/30], Loss: 0.1692\n",
      "Epoch [13/30], Loss: 0.1692\n",
      "Epoch [14/30], Loss: 0.1692\n",
      "Epoch [15/30], Loss: 0.1691\n",
      "Epoch [16/30], Loss: 0.1691\n",
      "Epoch [17/30], Loss: 0.1691\n",
      "Epoch [18/30], Loss: 0.1691\n",
      "Epoch [19/30], Loss: 0.1691\n",
      "Epoch [20/30], Loss: 0.1691\n",
      "Epoch [21/30], Loss: 0.1691\n",
      "Epoch [22/30], Loss: 0.1691\n",
      "Epoch [23/30], Loss: 0.1691\n",
      "Epoch [24/30], Loss: 0.1691\n",
      "Epoch [25/30], Loss: 0.1691\n",
      "Epoch [26/30], Loss: 0.1691\n",
      "Epoch [27/30], Loss: 0.1691\n",
      "Epoch [28/30], Loss: 0.1691\n",
      "Epoch [29/30], Loss: 0.1691\n",
      "Epoch [30/30], Loss: 0.1691\n",
      "Test NDCG@10: 0.3905\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Define the ListNet loss\n",
    "class ListNetLoss(nn.Module):\n",
    "    def __init__(self, k=10):\n",
    "        super(ListNetLoss, self).__init__()\n",
    "        self.k = k\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        y_pred = F.softmax(y_pred, dim=1)\n",
    "        y_true = F.softmax(y_true, dim=1)\n",
    "        return -torch.sum(y_true * torch.log(y_pred), dim=1).mean()\n",
    "\n",
    "# Define the hybrid recommender model\n",
    "class HybridRecommender(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim, num_features, num_layers, hidden_dims, dropout_prob):\n",
    "        super(HybridRecommender, self).__init__()\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_embedding = nn.Embedding(num_items, embedding_dim)\n",
    "\n",
    "        layers = []\n",
    "        input_dim = embedding_dim * 2 + num_features\n",
    "        for i in range(num_layers):\n",
    "            layers.append(nn.Linear(input_dim, hidden_dims[i]))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(p=dropout_prob))\n",
    "            input_dim = hidden_dims[i]\n",
    "        layers.append(nn.Linear(input_dim, 1))\n",
    "\n",
    "        self.fc_layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, user_ids, item_ids, features):\n",
    "        user_embedded = self.user_embedding(user_ids)\n",
    "        item_embedded = self.item_embedding(item_ids)\n",
    "        concat_features = torch.cat((user_embedded, item_embedded, features), dim=1)\n",
    "        output = self.fc_layers(concat_features)\n",
    "        return output.squeeze()\n",
    "\n",
    "# Assuming your DataFrame is named 'data'\n",
    "\n",
    "# Perform label encoding for 'user_id' and 'music_id' columns\n",
    "user_id_encoder = LabelEncoder()\n",
    "music_id_encoder = LabelEncoder()\n",
    "data['user_id_encoded'] = user_id_encoder.fit_transform(data['user_id'])\n",
    "data['music_id_encoded'] = music_id_encoder.fit_transform(data['music_id'])\n",
    "\n",
    "# Perform label encoding for 'gender' column\n",
    "gender_encoder = LabelEncoder()\n",
    "data['gender_encoded'] = gender_encoder.fit_transform(data['gender'])\n",
    "\n",
    "# Perform TF-IDF encoding for 'artist_name' and 'genre' columns\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "artist_tfidf = tfidf_vectorizer.fit_transform(data['artist_name'])\n",
    "genre_tfidf = tfidf_vectorizer.fit_transform(data['genre'])\n",
    "\n",
    "# Convert TF-IDF matrices to DataFrames\n",
    "artist_tfidf_df = pd.DataFrame(artist_tfidf.toarray(), columns=[f'artist_tfidf_{i}' for i in range(artist_tfidf.shape[1])])\n",
    "genre_tfidf_df = pd.DataFrame(genre_tfidf.toarray(), columns=[f'genre_tfidf_{i}' for i in range(genre_tfidf.shape[1])])\n",
    "\n",
    "# Concatenate the encoded DataFrames with the original DataFrame\n",
    "data_encoded = pd.concat([data[['user_id_encoded', 'music_id_encoded', 'age', 'gender_encoded', 'duration', 'acousticness', 'danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'time_signature', 'explicit', 'plays']], artist_tfidf_df, genre_tfidf_df], axis=1)\n",
    "\n",
    "# Split the data into features and target\n",
    "features = data_encoded.drop(columns=['plays'])\n",
    "target = data_encoded['plays']\n",
    "\n",
    "# Split the data into train and test sets\n",
    "train_data = features.sample(frac=0.8, random_state=42)\n",
    "test_data = features.drop(train_data.index)\n",
    "\n",
    "train_target = target[train_data.index]\n",
    "test_target = target[test_data.index]\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "train_data_tensor = torch.tensor(train_data.values, dtype=torch.float)\n",
    "test_data_tensor = torch.tensor(test_data.values, dtype=torch.float)\n",
    "train_target_tensor = torch.tensor(train_target.values, dtype=torch.float).unsqueeze(1)\n",
    "test_target_tensor = torch.tensor(test_target.values, dtype=torch.float).unsqueeze(1)\n",
    "\n",
    "# Extract user IDs, item IDs, and feature tensors\n",
    "train_user_ids = train_data_tensor[:, 0].long()\n",
    "train_item_ids = train_data_tensor[:, 1].long()\n",
    "train_features = train_data_tensor[:, 2:]\n",
    "\n",
    "test_user_ids = test_data_tensor[:, 0].long()\n",
    "test_item_ids = test_data_tensor[:, 1].long()\n",
    "test_features = test_data_tensor[:, 2:]\n",
    "\n",
    "# Initialize the model\n",
    "num_users = len(user_id_encoder.classes_)\n",
    "num_items = len(music_id_encoder.classes_)\n",
    "embedding_dim = 128\n",
    "num_layers = 3\n",
    "hidden_dims = [256, 128, 64]\n",
    "num_features = train_features.shape[1]\n",
    "dropout_prob = 0.2  # Ensure dropout_prob is defined\n",
    "\n",
    "model = HybridRecommender(num_users, num_items, embedding_dim, num_features, num_layers, hidden_dims, dropout_prob)\n",
    "\n",
    "# Train the model with ListNet loss\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "\n",
    "criterion = ListNetLoss(k=10)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "# Train the model with regularization and dropout\n",
    "num_epochs = 30\n",
    "batch_size = 128\n",
    "dropout_prob = 0.2\n",
    "for epoch in range(num_epochs):\n",
    "    for i in range(0, len(train_data), batch_size):\n",
    "        batch_user_ids = train_user_ids[i:i+batch_size].to(device)\n",
    "        batch_item_ids = train_item_ids[i:i+batch_size].to(device)\n",
    "        batch_features = train_features[i:i+batch_size].to(device)\n",
    "        batch_target = train_target_tensor[i:i+batch_size].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(batch_user_ids, batch_item_ids, batch_features)\n",
    "        loss = criterion(predictions.unsqueeze(1), batch_target)\n",
    "        # Add L2 regularization to the loss\n",
    "        l2_reg = torch.tensor(0.).to(device)\n",
    "        for param in model.parameters():\n",
    "            l2_reg += torch.norm(param)\n",
    "        loss += 1e-4 * l2_reg\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    scheduler.step()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Evaluate the model with NDCG@k\n",
    "def ndcg_at_k(y_true, y_pred, k):\n",
    "    y_true = y_true.reshape(-1)\n",
    "    y_pred = y_pred.reshape(-1)\n",
    "\n",
    "    indices = np.argsort(y_pred)[::-1]\n",
    "    y_true_sorted = y_true[indices]\n",
    "\n",
    "    gains = np.log2(y_true_sorted + 1)\n",
    "    discounts = np.log2(np.arange(len(y_true_sorted)) + 2)\n",
    "    dcg = np.sum(gains[:k] / discounts[:k])\n",
    "\n",
    "    ideal_gains = np.log2(np.sort(y_true)[::-1] + 1)\n",
    "    ideal_dcg = np.sum(ideal_gains[:k] / discounts[:k])\n",
    "\n",
    "    return dcg / ideal_dcg\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Move input tensors to the same device as the model\n",
    "    predictions = model(test_user_ids.to(device), test_item_ids.to(device), test_features.to(device))  \n",
    "    ndcg_score = ndcg_at_k(test_target_tensor.cpu().numpy(), predictions.cpu().numpy(), k=10) # Move target tensor to cpu for ndcg calculation\n",
    "    print(f\"Test NDCG@10: {ndcg_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "torch.save(model.state_dict(), 'model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate recommendations for a user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def get_recommendations(model, user_id, data_encoded, user_id_encoder, item_encoder, device, top_k=10):\n",
    "    \"\"\"\n",
    "    Generate top-k recommendations for a given user.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): Trained recommender model.\n",
    "        user_id (str): The user ID for whom to generate recommendations.\n",
    "        data_encoded (pd.DataFrame): The preprocessed and encoded dataset.\n",
    "        user_id_encoder (LabelEncoder): Fitted LabelEncoder for user IDs.\n",
    "        item_encoder (LabelEncoder): Fitted LabelEncoder for item IDs.\n",
    "        device (torch.device): Device where the model is loaded.\n",
    "        top_k (int): Number of top recommendations to return.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: List of recommended music IDs.\n",
    "    \"\"\"\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "\n",
    "    # Encode the user ID\n",
    "    try:\n",
    "        user_id_encoded = user_id_encoder.transform([user_id])[0]\n",
    "    except ValueError:\n",
    "        raise ValueError(f\"User ID {user_id} not found in encoder.\")\n",
    "\n",
    "    # Extract user features\n",
    "    user_data = data_encoded[data_encoded['user_id_encoded'] == user_id_encoded].drop(columns=['user_id_encoded', 'plays']).iloc[0]\n",
    "    user_features = torch.tensor(user_data.values, dtype=torch.float).unsqueeze(0).to(device)\n",
    "\n",
    "    # Prepare all item IDs\n",
    "    item_ids = torch.arange(len(item_encoder.classes_)).to(device)\n",
    "\n",
    "    # Create user and item tensors\n",
    "    user_ids = torch.tensor([user_id_encoded] * len(item_ids), dtype=torch.long).to(device)\n",
    "    item_ids = item_ids.long()\n",
    "\n",
    "    # Disable gradient computation\n",
    "    with torch.no_grad():\n",
    "        # Forward pass to get scores\n",
    "        scores = model(user_ids, item_ids, user_features.repeat(len(item_ids), 1))\n",
    "\n",
    "    # Get top-k scores and corresponding item IDs\n",
    "    top_scores, top_indices = torch.topk(scores, top_k)\n",
    "    top_item_ids_encoded = top_indices.cpu().numpy()\n",
    "\n",
    "    # Convert encoded item IDs back to original IDs\n",
    "    top_item_ids = item_encoder.inverse_transform(top_item_ids_encoded)\n",
    "\n",
    "    return top_item_ids.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    83811\n",
       "1    83811\n",
       "2    13397\n",
       "3    70645\n",
       "4    70645\n",
       "Name: user_id, dtype: category\n",
       "Categories (9741, int64): [4, 16, 35, 74, ..., 99980, 99996, 99997, 99998]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['user_id'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'item_encoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m top_k \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 8\u001b[0m     recommended_items \u001b[38;5;241m=\u001b[39m get_recommendations(model, user_id, data_encoded, user_id_encoder, \u001b[43mitem_encoder\u001b[49m, device, top_k)\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTop \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtop_k\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m recommendations for user \u001b[39m\u001b[38;5;132;01m{\u001b[39;00muser_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m recommended_items:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'item_encoder' is not defined"
     ]
    }
   ],
   "source": [
    "# Assuming the following variables are already defined and loaded:\n",
    "# model, user_id_encoder, item_encoder, data_encoded, device\n",
    "\n",
    "user_id = \"83811\"\n",
    "top_k = 10\n",
    "\n",
    "try:\n",
    "    recommended_items = get_recommendations(model, user_id, data_encoded, user_id_encoder, item_encoder, device, top_k)\n",
    "    print(f\"Top {top_k} recommendations for user {user_id}:\")\n",
    "    for item in recommended_items:\n",
    "        print(item)\n",
    "except ValueError as ve:\n",
    "    print(ve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Predictions: [1.317741e-13 1.317741e-13 1.317741e-13 1.317741e-13 1.317741e-13\n",
      " 1.317741e-13 1.317741e-13 1.317741e-13 1.317741e-13 1.317741e-13]\n"
     ]
    }
   ],
   "source": [
    "test_user_ids_sample = test_user_ids[:10]  # Adjust the number of samples as needed\n",
    "test_item_ids_sample = test_item_ids[:10]\n",
    "test_features_sample = test_features[:10]\n",
    "\n",
    "with torch.no_grad():\n",
    "    sample_predictions = model(test_user_ids_sample.to(device), test_item_ids_sample.to(device), test_features_sample.to(device))\n",
    "    print(\"Sample Predictions:\", sample_predictions.cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_inference(model, user_id, item_id, features, user_encoder, item_encoder, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    user_id_encoded = torch.tensor(user_encoder.transform([user_id]), dtype=torch.long).to(device)\n",
    "    item_id_encoded = torch.tensor(item_encoder.transform([item_id]), dtype=torch.long).to(device)\n",
    "    features_tensor = torch.tensor(features, dtype=torch.float).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        prediction = model(user_id_encoded, item_id_encoded, features_tensor)\n",
    "    return prediction.cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         3936\n",
       "1         4020\n",
       "2         6090\n",
       "3         8577\n",
       "4         2130\n",
       "         ...  \n",
       "19969     6901\n",
       "19970    10826\n",
       "19971     5836\n",
       "19972     8646\n",
       "19973     9213\n",
       "Name: music_id_encoded, Length: 19974, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['music_id_encoded']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        2fQrGHiQOvpL9UgPvtYy6G\n",
       "1        2ihCaVdNZmnHZWt0fvAM7B\n",
       "2        46jLy47W8rkf8rEX04gMKB\n",
       "3        5oVlbbiKGdGeZkWCFy0mqk\n",
       "4        1SNoSoQ3JZldOhzBY9gw0n\n",
       "                  ...          \n",
       "19969    4es5wreov9D4Y4fXLGZkuB\n",
       "19970    7JtQLJcOyVJKUPdUC4lggE\n",
       "19971    3wu9ADop1FXdhToPCxwBL8\n",
       "19972    5rXkgeY6rpcHcsolCpXZHR\n",
       "19973    6Ep6BzIOB9tz3P4sWqiiAB\n",
       "Name: music_id, Length: 19974, dtype: category\n",
       "Categories (11528, object): ['0010mZpCCwlPwoBiBsjoac', '0088Tt3QK3fMYodhkIEoUh', '00AivYmu1UVmxM91uhR9lM', '00BuKLSAFkaEkaVAgIMbeA', ..., '7zqB9qTuzWHwhddWf5FwWQ', '7zuwaenG5AF0vG7o7kMduX', '7zxRMhXxJMQCeDDg0rKAVo', '7zyja1IM5jwetBYGZJhxXP']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['music_id']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(user_id, top_k=10):\n",
    "    user_id_encoded = user_id_encoder.transform([user_id])[0]\n",
    "    user_data = data_encoded[data_encoded['user_id_encoded'] == user_id_encoded].drop(columns=['user_id_encoded', 'plays']).iloc[0]\n",
    "    user_tensor = torch.tensor(user_data.values, dtype=torch.float).unsqueeze(0)\n",
    "    \n",
    "    item_ids = torch.tensor(range(num_items), dtype=torch.long)\n",
    "    item_embeddings = model.item_embedding(item_ids)\n",
    "    user_embedding = model.user_embedding(torch.tensor([user_id_encoded], dtype=torch.long))\n",
    "    user_embedding_repeated = user_embedding.repeat(num_items, 1)\n",
    "    \n",
    "    scores = model.fc_layers(torch.cat((user_embedding_repeated, item_embeddings, user_tensor.repeat(num_items, 1)), dim=1))\n",
    "    \n",
    "    top_items = item_ids[scores.argsort(descending=True)][:top_k]\n",
    "    return top_items.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ReNeLLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
